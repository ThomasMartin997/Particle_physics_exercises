{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a039a5a5-d28b-4da7-91f8-19ab7ec79624",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DlKKs_CMCX_df.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m df_off = pd.read_pickle(\u001b[33m'\u001b[39m\u001b[33mDlKKs_off_df.p\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m df_dat = pd.read_pickle(\u001b[33m'\u001b[39m\u001b[33mDlKKs_data_df.p\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df_cmc = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDlKKs_CMCX_df.p\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#---------------------------------- Data lumi = 365.290, BB cross-section = 1050000.0, Offpeak lumi = 42.740 #144643/577965 = 0.2502625591515057\u001b[39;00m\n\u001b[32m     12\u001b[39m df_cc2 = pd.read_pickle(\u001b[33m'\u001b[39m\u001b[33mold/DlKKs_ccMC_df.p\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\belle2-analysis\\.venv\\Lib\\site-packages\\pandas\\io\\pickle.py:185\u001b[39m, in \u001b[36mread_pickle\u001b[39m\u001b[34m(filepath_or_buffer, compression, storage_options)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m4    4    9\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m excs_to_catch = (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\belle2-analysis\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'DlKKs_CMCX_df.p'"
     ]
    }
   ],
   "source": [
    "%run functions.ipynb\n",
    "# import b2plot as b2 -Was pretty lame plugin\n",
    "df_chg = pd.read_pickle('DlKKs_chgMC_df.p ')\n",
    "df_mix = pd.read_pickle('DlKKs_mixMC_df.p')\n",
    "df_cc = pd.read_pickle('DlKKs_ccMC_df.p')\n",
    "df_uds = pd.read_pickle('DlKKs_udsMC_df.p')\n",
    "df_off = pd.read_pickle('DlKKs_off_df.p')\n",
    "df_dat = pd.read_pickle('DlKKs_data_df.p')\n",
    "df_cmc = pd.read_pickle('DlKKs_CMCX_df.p')\n",
    "\n",
    "#---------------------------------- Data lumi = 365.290, BB cross-section = 1050000.0, Offpeak lumi = 42.740 #144643/577965 = 0.2502625591515057\n",
    "df_cc2 = pd.read_pickle('old/DlKKs_ccMC_df.p')\n",
    "df_chg2 = pd.read_pickle('old/DlKKs_chgMC_df.p')\n",
    "df_mix2 = pd.read_pickle('old/DlKKs_mixMC_df.p')\n",
    "df_dat2 = pd.read_pickle('old/DlKKs_data_df.p')\n",
    "#--------------------------------- Generic MC lumi = 1461.16, wtMC = 0.250, wtMCOff = 0.029\n",
    "datasmc = [df_chg,df_mix,df_cc,df_uds]\n",
    "df_names = [r\"$B^+B^-$\", r\"$B^0\\bar{B}^0$\", r\"$c\\bar{c}$\", r\"light $q\\bar{q}$ ($u,d,s$)\", r\"off-resonance\"]\n",
    "df_namesmc = [r\"$B^+B^-$\", r\"$B^0\\bar{B}^0$\", r\"$c\\bar{c}$\", r\"light $q\\bar{q}$ ($u,d,s$)\"]\n",
    "datasmc_old = [df_chg2,df_mix2,df_cc2] #3.99 more data \n",
    "api = pdg.connect()\n",
    "df_asim = df_cmc.copy() #(577965, 328) r x c initial\n",
    "labbin = ['Signal','Background']\n",
    "mc_weights1 = np.ndarray((577965,))\n",
    "mc_weights1.fill(0.25)\n",
    "mc_weights2 = np.ndarray((577965,))\n",
    "mc_weights2.fill(0.002737551)\n",
    "dat_weights1 = np.ndarray((144643,))\n",
    "dat_weights1.fill(0.002737551)\n",
    "sig_vars = ['nROE_Ch', 'nROE_ECL', 'nROE_KL', 'Q_ROE', 'M_ROE', 'Eextra_ROE', 'R2', 'cosTBTO',\n",
    "     'nROE_ECL_loose', 'M_ROE_loose', 'Eextra_ROE_loose',\n",
    "     'trkK0S_ECM', 'trkK0S_pCM', 'trkK0S_InvM', 'trkK0S_cosThCM', 'trkK0S_phiCM', 'trkK0S_charge',\n",
    "     'trkK0S_isSignal', 'trkK0S_isSignalAcceptMissing',\n",
    "     'trk_ECM', 'trk_pCM', 'trk_InvM', 'trk_cosThCM', 'trk_phiCM', 'trk_charge',\n",
    "     'trk_isSignal', 'trk_isSignalAcceptMissing', 'trk_dr', 'trk_d0Err', 'trk_dz',\n",
    "     'trk_nCDCHits', 'trk_nVXDHits', 'trk_ndf', 'trk_chi2', 'trk_lastCDCLayer',\n",
    "     'K0S_ECM', 'K0S_pCM', 'K0S_InvM', 'K0S_cosThCM', 'K0S_phiCM', 'K0S_charge',\n",
    "     'K0S_isSignal', 'K0S_isSignalAcceptMissing', 'K0S_chiProb', 'K0S_flightDistance',\n",
    "     'K0S_flightDistanceErr', 'K0S_dr', 'K0S_dz',\n",
    "     'nISR', 'cosK0Strk']\n",
    "\n",
    "tag = ['BSL_ECM', 'BSL_pCM', 'BSL_InvM', 'BSL_cosThCM', 'BSL_phiCM', 'BSL_charge',\n",
    "     'BSL_BchiProb', 'BSL_BflightDistance', 'BSL_BflightDistanceErr', 'BSL_Bdr', 'BSL_Bdz',\n",
    "     'BSL_isSignal', 'BSL_isSignalAcceptMissing', 'BSL_cosBY',\n",
    "     'eSL_ECM', 'eSL_pCM', 'eSL_InvM', 'eSL_cosThCM', 'eSL_phiCM', 'eSL_charge',\n",
    "     'eSL_isSignal', 'eSL_isSignalAcceptMissing',\n",
    "     'D0SL_ECM', 'D0SL_pCM', 'D0SL_InvM', 'D0SL_cosThCM', 'D0SL_phiCM', 'D0SL_charge',\n",
    "     'D0SL_DchiProb', 'D0SL_DflightDistance', 'D0SL_DflightDistanceErr',\n",
    "     'D0SL_Ddr', 'D0SL_Ddz', 'D0SL_isSignal', 'D0SL_isSignalAcceptMissing',\n",
    "     'cosK0SeSL', 'cosK0SD0SL']\n",
    "\n",
    "df_asim = set_modes_sig(df_asim)\n",
    "\"\"\"Alternative Implementation for function\"\"\"\n",
    "    # bplus_dict = {}\n",
    "    # bminus_dict = {}\n",
    "    # b0_dict = {}\n",
    "    # bbar0_dict = {}\n",
    "    # bs0_dict = {}\n",
    "    # bsbar0_dict = {}\n",
    "    # d0_dict = {}\n",
    "    # dbar0_dict = {}\n",
    "    # dminus_dict = {}\n",
    "    # dplus_dict = {}\n",
    "    # dsminus_dict = {}\n",
    "    # dsplus_dict = {}\n",
    "    # dstminus_dict = {}\n",
    "    # dstplus_dict = {}\n",
    "    # tplus_dict = {}\n",
    "    # tminus_dict = {}\n",
    "    \n",
    "    # dec_tag_dicts = [\n",
    "    # bplus_dict,bminus_dict,\n",
    "    # b0_dict,bbar0_dict,\n",
    "    # bs0_dict,bsbar0_dict,\n",
    "    # dstplus_dict,dstminus_dict,\n",
    "    # dsplus_dict,dsminus_dict,\n",
    "    # dplus_dict,dminus_dict,\n",
    "    # d0_dict,dbar0_dict,\n",
    "    # tplus_dict,tminus_dict]\n",
    "    # parents = [\n",
    "    #     r'B^{+}\\rightarrow',r'B^{-}\\rightarrow',\n",
    "    #     r'B^{0}\\rightarrow',r'\\bar{B}^{0}\\rightarrow',\n",
    "    #     r'B^{0}_{s}\\rightarrow',r'\\bar{B}^{0}_{s}\\rightarrow',\n",
    "    #     r'D^{*+}\\rightarrow',r'D^{*-}\\rightarrow',\n",
    "    #     r'D^{+}_{s}\\rightarrow',r'D^{-}_{s}\\rightarrow',\n",
    "    #     r'D^{+}\\rightarrow',r'D^{-}\\rightarrow',\n",
    "    #     r'D^{0}\\rightarrow',r'\\bar{D}^{0}\\rightarrow',\n",
    "    #     r'\\tau^{+}\\rightarrow',r'\\tau^{-}\\rightarrow'\n",
    "    # ]\n",
    "\n",
    "    # dec_tag_files = [\n",
    "    #     'BplusTag.tex','BminusTag.tex',\n",
    "    #     'B0Tag.tex','Bbar0Tag.tex',\n",
    "    #     'Bs0Tag.tex','Bsbar0Tag.tex',\n",
    "    #     'DstplusTag.tex','DstminusTag.tex',\n",
    "    #     'DsplusTag.tex','DsminusTag.tex',\n",
    "    #     'DplusTag.tex','DminusTag.tex',\n",
    "    #     'D0Tag.tex','Dbar0Tag.tex',\n",
    "    # 'TauplusTag.tex','TauminusTag.tex']\n",
    "    # decay_ids = 'all_decays.csv'\n",
    "    # unidentified = [*range(1,31,), 99]\n",
    "    # for fi, di, tag in zip(dec_tag_files, dec_tag_dicts, parents):\n",
    "    #     with open(filepath+fi, encoding='utf-8') as fh:\n",
    "    #         for line in fh:\n",
    "    #             if \"$\" in line:\n",
    "    #                 decay = line.split(\"$ \")[1]\n",
    "    #                 mode, modeid = decay.split(\"\\\\hfill\")\n",
    "    #                 mode, modeid = mode.strip(), modeid.strip(\"{}$ \\n\")[1:]\n",
    "    #                 #di[int(modeid)] = f\"{tag} {mode}\"\n",
    "\n",
    "    #                 with open(\"all_decays.csv\", \"a\") as f: #This exploits that all decay modes for each parent start at 1001 to sep each file\n",
    "    #                     if int(modeid) == 1001:\n",
    "    #                         type_dec = fi.split('Tag')[0]\n",
    "    #                         f.write(type_dec+',Decay ID\\n')# Vertically seperated order\n",
    "    #                         for num in unidentified: #Put unknown daughter modes upto 100 + not found mode for each\n",
    "    #                             if num != 99:\n",
    "    #                                 line = f'{tag} {num} \\\\: Daughters'\n",
    "    #                                 f.write(line+','+str(num)+'\\n')\n",
    "    #                                 di[int(num)] = line\n",
    "    #                             else:\n",
    "    #                                 line = f'-99:\\\\:Particle\\\\:Not\\\\:Found'\n",
    "    #                                 f.write(line+','+str(num)+'\\n')\n",
    "    #                                 di[int(num)] = line\n",
    "    #                     #For FSR inclusion its N00000 + ModeID, so \"in method\" is best\n",
    "    #                     f.write(tag + ' ' + mode + ',' + modeid+'\\n')\n",
    "    #                 di[int(modeid)] = f\"{tag} {mode}\"\n",
    "    \n",
    "    # return dec_tag_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86082ea-9b9d-4114-afd6-7f99a2d535ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode_dicts(filepath = ''): # Ordered keys as: Bplus, Bminus, B0, Bbar0, Bs0, Bsbar0, Dstplus, Dstminus, Dsplus, Dsminus, Dplus, Dminus, D0, Dbar0, Tauplus, Tauminus\n",
    "\n",
    "    #https://docs.belle2.org/files/541/BELLE2-NOTE-TE-2021-002/1/BELLE2-NOTE-TE-2021-002.pdf referenced from MC gen tag tool in BASF2, tex files from MC gen Tag tool\n",
    "    #basf2/analysis/utility/src/GenBsTag.cc\n",
    "    \"\"\"Note: This is one way to scan and get the corresponding decay files from the published tool relating to the internal note on gitlab. \n",
    "    However, one could in theory do the same thing on the files in BASF2. \n",
    "\n",
    "    To do this, goto Basf2 in gitlab. Then analysis/utility/. The tool GENMCTAG is mostly in the src files as GenBplusTag.cc\n",
    "    Going through each raw file with a scan or by calling the methods and getting the corresponding decay and string is another way. \n",
    "    Will implement if time, along with a reverse look up. Ie, input decay string, get ID.\n",
    "    if (GenBsTag::PcheckDecay(genpart, -10431, -15, 16)) {\n",
    "    return +1 * (100000 * m_nPhotos + 1016); is how its done in the basf2 implementation. \n",
    "    So, going through the list iteratively as how they've designed it with a PDG hash table of the particles would be \n",
    "    rather simple for a next and more robust iteration. Specifically incase the tool is updated in basf2 only but not in the publication files on gitlab. \n",
    "    \n",
    "    For now, I've attached a simple method to demonstrate using this function to show decay strings\n",
    "    Originally this was done using a bunch of dictionaries but I swapped to a nested version where you can specify the mother rather than the index.\n",
    "    I also included the mother and an arrow in the decay string, but left in the commented version without that which is more concise and implies the mother \n",
    "    in the correct context.\n",
    "    # update: I made it more concise and read through a CSV I generated with the old method - Downside is would need updated with some changes if more added. \n",
    "    \"\"\"\n",
    "    \n",
    "    master_dict = {\n",
    "    'Bplus': {},'Bminus': {},\n",
    "    'B0': {},'Bbar0': {},\n",
    "    'Bs0': {},'Bsbar0': {},\n",
    "    'Dstplus': {},'Dstminus': {},\n",
    "    'Dsplus': {},'Dsminus': {},\n",
    "    'Dplus': {},'Dminus': {},\n",
    "    'D0': {},'Dbar0': {},\n",
    "    'Tauplus': {},'Tauminus': {}}\n",
    "    with open(filepath+'all_decays.csv',encoding='utf-8') as fh:\n",
    "            for line in fh:\n",
    "                line = line.strip()\n",
    "                if 'Decay ID' in line:\n",
    "                    key = line.split(',')[0]\n",
    "                    continue\n",
    "                mode, modeid = line.split(',')\n",
    "                master_dict[key][int(modeid)] = mode\n",
    "\n",
    "\n",
    "    return master_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672eb9fe-f096-4a6d-a7c1-c4732c17fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = get_mode_dicts()\n",
    "# i = 0\n",
    "# for key, modes in x.items():\n",
    "#     for mode in modes.values():\n",
    "#         i += 1\n",
    "#         display(Math(mode))\n",
    "#         if i == 31 :\n",
    "#             break\n",
    "#     if i > 50:\n",
    "#        break\n",
    "#\n",
    "# y = x['Bplus'][1001]\n",
    "# label = f\"${y}$\"\n",
    "# label, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480cbf80-7b5e-4208-a7e8-e014cecf5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_modes = get_mode_dicts()\n",
    "\n",
    "def sel_ini(df):\n",
    "    df_t = df.copy()\n",
    "    df_t = df_t.query('(K0S_InvM > 0.489) & (K0S_InvM < 0.5056) & (BSL_BchiProb > 1e-8) & (nROE_Ch == 0) & (Eextra_ROE < 0.93) & (Eextra_ROE_loose < 1.84)')\n",
    "    df_t = df_t.query('(BSL_cosBY > -3) & (BSL_cosBY < 1.1) & (M_ROE_loose < 6.58) & (M_ROE < 4) & (K0S_flightDistance > 0.14) & (K0S_flightDistanceErr < 0.5) & (R2 < 0.73)')\n",
    "    df_t = df_t.query('(trk_dz > -1.8) & (trk_dz < 1.8) & (K0S_dz > -6.8) & (K0S_dz < 3.4) & (K0S_dr < 9.3) & (trkK0S_ECM < 20)')\n",
    "    df_t = df_t.query('(K0S_pCM < 2.5) & (trk_pCM < 2.5) & (eSL_pCM < 2.5) & (nROE_KL) < 12')\n",
    "    return df_t\n",
    "    \n",
    "sel_ini0 = sel_ini(df_asim)\n",
    "\n",
    "modes = 40\n",
    "\n",
    "top_twent = sel_ini0['signal'].value_counts().head(modes)\n",
    "cols = top_twent.index\n",
    "vals = top_twent.values\n",
    "col2 = [f\"${all_modes['Bplus'][abs(col)]}$\" for col in cols]\n",
    "#So the general way is just f\"${dict[mother][abs(mode_id)]$\" \n",
    "\n",
    "\"\"\"In general, you just access it by doing my_dict['Bplus etc'][mode] and loop through all modes you're interested in, getting them as I did. (Make sure to absolute value the modes)\"\"\"\n",
    "#example below\n",
    "fig4 = plt.figure(figsize=(26, 12))\n",
    "plt.barh(range(len(vals)), vals, color='skyblue', edgecolor='black', label='Positive B for simplification')\n",
    "plt.xlabel(\"Candidates\", fontsize=12)\n",
    "plt.ylabel(\"Decay Mode\", fontsize=12)\n",
    "plt.title(f'Top {modes} decay modes for signal side B candidates after selections')\n",
    "plt.yticks(range(len(col2)), col2, fontsize=10)\n",
    "plt.tight_layout()\n",
    "fig4.savefig(\"show4.pdf\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0abb6e-99a2-46d9-a153-7189d768bcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269d834-5e21-449d-acbc-3e3cb00feac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
